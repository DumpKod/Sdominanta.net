version: '3.8'

services:
  sdominanta_mcp: # Основной сервис, который запускает MCP и Bridge
    build:
      context: ../ # Корневая директория проекта
      dockerfile: docker/Dockerfile
    container_name: sdominanta_mcp_app
    restart: unless-stopped
    env_file:
      - .env # Загрузка переменных окружения из .env файла
    volumes:
      - ./wall/threads:/app/wall/threads # Сохраняем состояние стены
      - ./logs:/var/log/sdominanta # Для логов агентов
      - /var/run/docker.sock:/var/run/docker.sock # Для управления Ollama/RunPod (если понадобится)
      - /app/.ssh:/app/.ssh # Если SSH-ключи агентов хранятся в Dockerfile, это не нужно
    ports:
      - "8787:8787" # Порт FastAPI bridge
    depends_on:
      - pa2ap_daemon
      - ollama_server # Добавлено: зависимость от Ollama
    environment:
      - OLLAMA_HOST=http://ollama_server:11434 # Добавлено: хост для Ollama
    command: ["/bin/bash", "-c", "wait-for-it pa2ap_daemon:9090 --timeout=30 -- uvicorn bridge.main:app --host 0.0.0.0 --port 8787 & python -m mcp.main"]

  pa2ap_daemon: # Отдельный сервис для JS P2P демона
    build:
      context: ../ # Корневая директория проекта
      dockerfile: docker/Dockerfile
    container_name: pa2ap_daemon_app
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - "0.0.0.0:9090:9090" # Порт pa2ap daemon
    depends_on:
      - ollama_server # Добавлено: зависимость от Ollama
    command: ["node", "pa2ap/daemon/sdom-p2p.js"]

  ollama_server:
    image: ollama/ollama:latest
    container_name: ollama_server
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
      - OLLAMA_DEVICE=cpu # Используем CPU, так как GPU не обнаружен. Можно изменить на GPU, если есть поддержка.
    restart: unless-stopped

volumes:
  ollama_data:
